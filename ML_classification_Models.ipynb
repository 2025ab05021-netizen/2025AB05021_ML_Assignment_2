{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f29e6e30",
      "metadata": {
        "id": "f29e6e30"
      },
      "source": [
        "# Machine Learning Classification Assignment\n",
        "\n",
        "**Student Information:**\n",
        "- BITS ID: 2025AB05021\n",
        "- Name: Bhavani Mallem\n",
        "- Email: 2025ab05021@wilp.bits-pilani.ac.in\n",
        "- Date: 6 Feb 2026\n",
        "\n",
        "## Assignment Overview\n",
        "This notebook implements 6 different classification models and evaluates them on a chosen dataset:\n",
        "1. Logistic Regression\n",
        "2. Decision Tree Classifier\n",
        "3. K-Nearest Neighbor Classifier\n",
        "4. Naive Bayes Classifier\n",
        "5. Random Forest Classifier\n",
        "6. XGBoost Classifier\n",
        "\n",
        "Each model will be evaluated using:\n",
        "- Accuracy\n",
        "- AUC Score\n",
        "- Precision\n",
        "- Recall\n",
        "- F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12e3409",
      "metadata": {
        "id": "d12e3409"
      },
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "62fb17b3",
      "metadata": {
        "id": "62fb17b3",
        "outputId": "a9e94d0f-1fcb-4a7d-c494-324b564bae51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score,\n",
        "    recall_score, f1_score, classification_report,\n",
        "    confusion_matrix, roc_curve, auc\n",
        ")\n",
        "\n",
        "# Utilities\n",
        "import warnings\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e81ae50",
      "metadata": {
        "id": "2e81ae50"
      },
      "source": [
        "## 2. Dataset Selection and Loading\n",
        "\n",
        "For this assignment, I'll use the **Diabetes Dataset** which is a binary classification problem with health indicators.\n",
        "\n",
        "**Dataset Details:**\n",
        "- **Source**: UCI Machine Learning Repository / Kaggle\n",
        "- **Features**: 21+ features including BMI, age, smoking history, glucose levels, etc.\n",
        "- **Instances**: 100,000+ instances\n",
        "- **Target**: Binary classification (diabetes: 0 = No, 1 = Yes)\n",
        "- **Problem Type**: Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4918bdcb",
      "metadata": {
        "id": "4918bdcb"
      },
      "outputs": [],
      "source": [
        "# Load the Breast Cancer Wisconsin dataset from scikit-learn\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the dataset\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
        "df['target'] = cancer_data.target\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Features: {df.shape[1] - 1}\")\n",
        "print(f\"Samples: {df.shape[0]}\")\n",
        "\n",
        "print(f\"\\nTarget classes: {cancer_data.target_names}\")\n",
        "print(f\"Target mapping: 0 = {cancer_data.target_names[0]}, 1 = {cancer_data.target_names[1]}\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10f3bc4",
      "metadata": {
        "id": "b10f3bc4"
      },
      "outputs": [],
      "source": [
        "# Explore the dataset\n",
        "print(\"Dataset Description:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nTarget Variable Distribution:\")\n",
        "print(df['target'].value_counts())\n",
        "print(f\"\\nClass Balance:\")\n",
        "class_counts = df['target'].value_counts(normalize=True)\n",
        "print(f\"Malignant (0): {class_counts[0]:.3f}\")\n",
        "print(f\"Benign (1): {class_counts[1]:.3f}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum().sum(), \"total missing values\")\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData Types:\")\n",
        "print(\"All features are numeric - no encoding needed!\")\n",
        "print(f\"Feature data types: {df.dtypes.value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb5947e",
      "metadata": {
        "id": "7bb5947e"
      },
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b62b490",
      "metadata": {
        "id": "3b62b490"
      },
      "outputs": [],
      "source": [
        "# Create a copy for preprocessing\n",
        "data = df.copy()\n",
        "\n",
        "# Check for categorical variables (should be none for this dataset)\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "if 'target' in categorical_columns:\n",
        "    categorical_columns.remove('target')\n",
        "\n",
        "print(f\"Categorical columns: {categorical_columns}\")\n",
        "\n",
        "# Since Breast Cancer dataset has only numeric features, no encoding needed\n",
        "if categorical_columns:\n",
        "    # Encode categorical variables if any exist\n",
        "    label_encoders = {}\n",
        "    for col in categorical_columns:\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "        label_encoders[col] = le\n",
        "        print(f\"Encoded {col}: {le.classes_}\")\n",
        "else:\n",
        "    print(\"No categorical variables found - all features are numeric!\")\n",
        "    label_encoders = {}\n",
        "\n",
        "print(\"\\nDataset after preprocessing:\")\n",
        "print(data.head())\n",
        "print(f\"Shape: {data.shape}\")\n",
        "print(f\"Data types: {data.dtypes.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb25312",
      "metadata": {
        "id": "0eb25312"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Feature names: {X.columns.tolist()[:5]}...\") # Show first 5 feature names\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Training target distribution: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Test target distribution: {y_test.value_counts().to_dict()}\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nFeatures scaled successfully!\")\n",
        "print(f\"Feature scaling - Original range example: {X_train.iloc[0, 0]:.2f}\")\n",
        "print(f\"Feature scaling - Scaled range example: {X_train_scaled[0, 0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053f3f43",
      "metadata": {
        "id": "053f3f43"
      },
      "source": [
        "## 4. Model Implementation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d70cf8e",
      "metadata": {
        "id": "9d70cf8e"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    \"\"\"Evaluate a model and return metrics\"\"\"\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # AUC score\n",
        "    if y_pred_proba is not None:\n",
        "        auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    else:\n",
        "        auc = \"N/A\"\n",
        "\n",
        "    results = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'AUC Score': auc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"AUC Score: {auc if isinstance(auc, str) else f'{auc:.4f}'}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return results, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11e929d9",
      "metadata": {
        "id": "11e929d9"
      },
      "source": [
        "### 4.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a8ce1b",
      "metadata": {
        "id": "35a8ce1b"
      },
      "outputs": [],
      "source": [
        "# 1. Logistic Regression\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_results, lr_fitted = evaluate_model(\n",
        "    lr_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Logistic Regression\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "220054ba",
      "metadata": {
        "id": "220054ba"
      },
      "source": [
        "### 4.2 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd9a11f",
      "metadata": {
        "id": "ebd9a11f"
      },
      "outputs": [],
      "source": [
        "# 2. Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
        "dt_results, dt_fitted = evaluate_model(\n",
        "    dt_model, X_train, X_test, y_train, y_test, \"Decision Tree\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "025878d7",
      "metadata": {
        "id": "025878d7"
      },
      "source": [
        "### 4.3 K-Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6654aa9",
      "metadata": {
        "id": "a6654aa9"
      },
      "outputs": [],
      "source": [
        "# 3. K-Nearest Neighbors Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_results, knn_fitted = evaluate_model(\n",
        "    knn_model, X_train_scaled, X_test_scaled, y_train, y_test, \"K-Nearest Neighbors\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0abf7f8e",
      "metadata": {
        "id": "0abf7f8e"
      },
      "source": [
        "### 4.4 Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa585b86",
      "metadata": {
        "id": "aa585b86"
      },
      "outputs": [],
      "source": [
        "# 4. Naive Bayes Classifier (Gaussian)\n",
        "nb_model = GaussianNB()\n",
        "nb_results, nb_fitted = evaluate_model(\n",
        "    nb_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Naive Bayes (Gaussian)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d75d63",
      "metadata": {
        "id": "e7d75d63"
      },
      "source": [
        "### 4.5 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35423ed",
      "metadata": {
        "id": "c35423ed"
      },
      "outputs": [],
      "source": [
        "# 5. Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_results, rf_fitted = evaluate_model(\n",
        "    rf_model, X_train, X_test, y_train, y_test, \"Random Forest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb3038d2",
      "metadata": {
        "id": "bb3038d2"
      },
      "source": [
        "### 4.6 XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e09d88",
      "metadata": {
        "id": "80e09d88"
      },
      "outputs": [],
      "source": [
        "# 6. XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "xgb_results, xgb_fitted = evaluate_model(\n",
        "    xgb_model, X_train, X_test, y_train, y_test, \"XGBoost\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adbfca04",
      "metadata": {
        "id": "adbfca04"
      },
      "source": [
        "## 5. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0611026e",
      "metadata": {
        "id": "0611026e"
      },
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "all_results = [lr_results, dt_results, knn_results, nb_results, rf_results, xgb_results]\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.round(4)\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\" * 80)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Identify best models\n",
        "print(f\"\\nBest Models:\")\n",
        "print(f\"Highest Accuracy: {results_df.loc[results_df['Accuracy'].idxmax(), 'Model']} ({results_df['Accuracy'].max():.4f})\")\n",
        "print(f\"Highest AUC: {results_df.loc[results_df['AUC'].idxmax(), 'Model']} ({results_df['AUC'].max():.4f})\")\n",
        "print(f\"Highest F1: {results_df.loc[results_df['F1 Score'].idxmax(), 'Model']} ({results_df['F1 Score'].max():.4f})\")\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151f80f3",
      "metadata": {
        "id": "151f80f3"
      },
      "source": [
        "## 6. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e5108d",
      "metadata": {
        "id": "98e5108d"
      },
      "outputs": [],
      "source": [
        "# Create visualization of results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics = ['Accuracy', 'AUC Score', 'Precision', 'Recall', 'F1 Score']\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    if metric == 'AUC Score':\n",
        "        # Handle AUC score which might have N/A values\n",
        "        plot_data = results_df[results_df[metric] != 'N/A'].copy()\n",
        "        plot_data[metric] = plot_data[metric].astype(float)\n",
        "    else:\n",
        "        plot_data = results_df.copy()\n",
        "\n",
        "    if not plot_data.empty:\n",
        "        bars = axes[i].bar(plot_data['Model'], plot_data[metric],\n",
        "                          color=plt.cm.Set3(np.linspace(0, 1, len(plot_data))))\n",
        "        axes[i].set_title(f'{metric} by Model', fontweight='bold')\n",
        "        axes[i].set_ylabel(metric)\n",
        "        axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            axes[i].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                        f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Remove empty subplot\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the results for the Streamlit app\n",
        "results_df.to_csv('model_results.csv', index=False)\n",
        "print(\"\\nResults saved to model_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36806569",
      "metadata": {
        "id": "36806569"
      },
      "source": [
        "## 7. Save Models and Preprocessors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c612ca",
      "metadata": {
        "id": "d2c612ca"
      },
      "outputs": [],
      "source": [
        "# Save models and preprocessors for the Streamlit app\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# Save fitted models\n",
        "models_dict = {\n",
        "    'logistic_regression': lr_fitted,\n",
        "    'decision_tree': dt_fitted,\n",
        "    'knn': knn_fitted,\n",
        "    'naive_bayes': nb_fitted,\n",
        "    'random_forest': rf_fitted,\n",
        "    'xgboost': xgb_fitted\n",
        "}\n",
        "\n",
        "# Save each model\n",
        "for name, model in models_dict.items():\n",
        "    joblib.dump(model, f'{name}_model.pkl')\n",
        "    print(f\"Saved {name} model\")\n",
        "\n",
        "# Save preprocessors\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "\n",
        "# Save feature names and other metadata\n",
        "metadata = {\n",
        "    'feature_names': X.columns.tolist(),\n",
        "    'categorical_columns': categorical_columns,\n",
        "    'target_classes': ['No Diabetes', 'Diabetes']\n",
        "}\n",
        "\n",
        "with open('metadata.pkl', 'wb') as f:\n",
        "    pickle.dump(metadata, f)\n",
        "\n",
        "print(\"\\nAll models and preprocessors saved successfully!\")\n",
        "print(\"Ready to build Streamlit app.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}