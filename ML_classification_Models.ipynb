{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29e6e30",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Assignment\n",
    "\n",
    "**Student Information:**\n",
    "- BITS ID: 2025AB05021\n",
    "- Name: Bhavani Mallem\n",
    "- Email: 2025ab05021@wilp.bits-pilani.ac.in\n",
    "- Date: 6 Feb 2026\n",
    "\n",
    "## Assignment Overview\n",
    "This notebook implements 6 different classification models and evaluates them on a chosen dataset:\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. K-Nearest Neighbor Classifier\n",
    "4. Naive Bayes Classifier\n",
    "5. Random Forest Classifier\n",
    "6. XGBoost Classifier\n",
    "\n",
    "Each model will be evaluated using:\n",
    "- Accuracy\n",
    "- AUC Score\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e3409",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fb17b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/mbhava16/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <58FE87DD-A5B4-3D80-BC4B-11FC831B9707> /Users/mbhava16/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaive_bayes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianNB, MultinomialNB\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Evaluation metrics\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     accuracy_score, roc_auc_score, precision_score, \n\u001b[32m     23\u001b[39m     recall_score, f1_score, classification_report, \n\u001b[32m     24\u001b[39m     confusion_matrix, roc_curve\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/core.py:308\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/core.py:270\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    269\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    271\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    284\u001b[39m         )\n\u001b[32m    285\u001b[39m     _register_log_callback(lib)\n\u001b[32m    287\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/mbhava16/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <58FE87DD-A5B4-3D80-BC4B-11FC831B9707> /Users/mbhava16/Documents/MTech Assignments/DNN_Assignment/Assignmen2/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, \n",
    "    recall_score, f1_score, classification_report, \n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81ae50",
   "metadata": {},
   "source": [
    "## 2. Dataset Selection and Loading\n",
    "\n",
    "For this assignment, I'll use the **Diabetes Dataset** which is a binary classification problem with health indicators.\n",
    "\n",
    "**Dataset Details:**\n",
    "- **Source**: UCI Machine Learning Repository / Kaggle\n",
    "- **Features**: 21+ features including BMI, age, smoking history, glucose levels, etc.\n",
    "- **Instances**: 100,000+ instances\n",
    "- **Target**: Binary classification (diabetes: 0 = No, 1 = Yes)\n",
    "- **Problem Type**: Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Diabetes prediction dataset\n",
    "# Using a publicly available diabetes dataset with sufficient features\n",
    "try:\n",
    "    # First try loading from local if available\n",
    "    df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "    print(\"Loaded dataset from local file\")\n",
    "except FileNotFoundError:\n",
    "    # If not available locally, create URL to download\n",
    "    url = \"https://raw.githubusercontent.com/VenkateshDas/diabetes-prediction/main/diabetes_prediction_dataset.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"Downloaded dataset from GitHub\")\n",
    "    # Save locally for future use\n",
    "    df.to_csv('diabetes_prediction_dataset.csv', index=False)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.shape[1] - 1}\")\n",
    "print(f\"Samples: {df.shape[0]}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset Description:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(df['diabetes'].value_counts())\n",
    "print(f\"\\nClass Balance:\")\n",
    "print(df['diabetes'].value_counts(normalize=True))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb5947e",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "data = df.copy()\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'diabetes' in categorical_columns:\n",
    "    categorical_columns.remove('diabetes')\n",
    "\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {le.classes_}\")\n",
    "\n",
    "print(\"\\nAfter encoding:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb25312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('diabetes', axis=1)\n",
    "y = data['diabetes']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f3f43",
   "metadata": {},
   "source": [
    "## 4. Model Implementation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Evaluate a model and return metrics\"\"\"\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # AUC score\n",
    "    if y_pred_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        auc = \"N/A\"\n",
    "    \n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC Score': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC Score: {auc if isinstance(auc, str) else f'{auc:.4f}'}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e929d9",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_results, lr_fitted = evaluate_model(\n",
    "    lr_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220054ba",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "dt_results, dt_fitted = evaluate_model(\n",
    "    dt_model, X_train, X_test, y_train, y_test, \"Decision Tree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025878d7",
   "metadata": {},
   "source": [
    "### 4.3 K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6654aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. K-Nearest Neighbors Classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_results, knn_fitted = evaluate_model(\n",
    "    knn_model, X_train_scaled, X_test_scaled, y_train, y_test, \"K-Nearest Neighbors\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf7f8e",
   "metadata": {},
   "source": [
    "### 4.4 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa585b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Naive Bayes Classifier (Gaussian)\n",
    "nb_model = GaussianNB()\n",
    "nb_results, nb_fitted = evaluate_model(\n",
    "    nb_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Naive Bayes (Gaussian)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d75d63",
   "metadata": {},
   "source": [
    "### 4.5 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35423ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_results, rf_fitted = evaluate_model(\n",
    "    rf_model, X_train, X_test, y_train, y_test, \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3038d2",
   "metadata": {},
   "source": [
    "### 4.6 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e09d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_results, xgb_fitted = evaluate_model(\n",
    "    xgb_model, X_train, X_test, y_train, y_test, \"XGBoost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfca04",
   "metadata": {},
   "source": [
    "## 5. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = [lr_results, dt_results, knn_results, nb_results, rf_results, xgb_results]\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identify best models\n",
    "print(f\"\\nBest Models:\")\n",
    "print(f\"Highest Accuracy: {results_df.loc[results_df['Accuracy'].idxmax(), 'Model']} ({results_df['Accuracy'].max():.4f})\")\n",
    "print(f\"Highest AUC: {results_df.loc[results_df['AUC'].idxmax(), 'Model']} ({results_df['AUC'].max():.4f})\")\n",
    "print(f\"Highest F1: {results_df.loc[results_df['F1 Score'].idxmax(), 'Model']} ({results_df['F1 Score'].max():.4f})\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f80f3",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'AUC Score', 'Precision', 'Recall', 'F1 Score']\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    if metric == 'AUC Score':\n",
    "        # Handle AUC score which might have N/A values\n",
    "        plot_data = results_df[results_df[metric] != 'N/A'].copy()\n",
    "        plot_data[metric] = plot_data[metric].astype(float)\n",
    "    else:\n",
    "        plot_data = results_df.copy()\n",
    "    \n",
    "    if not plot_data.empty:\n",
    "        bars = axes[i].bar(plot_data['Model'], plot_data[metric], \n",
    "                          color=plt.cm.Set3(np.linspace(0, 1, len(plot_data))))\n",
    "        axes[i].set_title(f'{metric} by Model', fontweight='bold')\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[i].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the results for the Streamlit app\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "print(\"\\nResults saved to model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36806569",
   "metadata": {},
   "source": [
    "## 7. Save Models and Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c612ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and preprocessors for the Streamlit app\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Save fitted models\n",
    "models_dict = {\n",
    "    'logistic_regression': lr_fitted,\n",
    "    'decision_tree': dt_fitted,\n",
    "    'knn': knn_fitted,\n",
    "    'naive_bayes': nb_fitted,\n",
    "    'random_forest': rf_fitted,\n",
    "    'xgboost': xgb_fitted\n",
    "}\n",
    "\n",
    "# Save each model\n",
    "for name, model in models_dict.items():\n",
    "    joblib.dump(model, f'{name}_model.pkl')\n",
    "    print(f\"Saved {name} model\")\n",
    "\n",
    "# Save preprocessors\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "\n",
    "# Save feature names and other metadata\n",
    "metadata = {\n",
    "    'feature_names': X.columns.tolist(),\n",
    "    'categorical_columns': categorical_columns,\n",
    "    'target_classes': ['No Diabetes', 'Diabetes']\n",
    "}\n",
    "\n",
    "with open('metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"\\nAll models and preprocessors saved successfully!\")\n",
    "print(\"Ready to build Streamlit app.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
